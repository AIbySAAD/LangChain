{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class SearchTool(BaseModel):\n",
    "    \"\"\"Look up things online, optionally returning directly\"\"\"\n",
    "\n",
    "    query: str = Field(description=\"query to look up online\")\n",
    "    return_direct: bool = Field(\n",
    "        description=\"Whether or the result of this should be returned directly to the user without you seeing what it is\",\n",
    "        default=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tools = [TavilySearchResults(max_results=1,args_schema=SearchTool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolExecutor\n",
    "tool_executor=ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model=ChatOpenAI(temperature=0.7,streaming=True)\n",
    "model=model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    \"\"\"Final response to the user\"\"\"\n",
    "\n",
    "    temperature: float = Field(description=\"the temperature\")\n",
    "    other_notes: str = Field(description=\"any other notes about the weather\")\n",
    "\n",
    "\n",
    "model = model.bind_tools(tools + [Response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict,Sequence,Annotated\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agentstate(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage],operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state) -> Literal[\"continue\", \"end\"]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    if last_message.tool_calls[0][\"name\"] == \"Response\":\n",
    "        return \"end\"\n",
    "    return \"continue\"\n",
    "    \n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"][-5:]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_tool(state):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    tool_invocations = []\n",
    "    for tool_call in last_message.tool_calls:\n",
    "        action = ToolInvocation(\n",
    "            tool=tool_call[\"name\"],\n",
    "            tool_input=tool_call[\"args\"],\n",
    "        )\n",
    "        tool_invocations.append(action)\n",
    "\n",
    "    action = ToolInvocation(\n",
    "        tool=tool_call[\"name\"],\n",
    "        tool_input=tool_call[\"args\"],\n",
    "    )\n",
    "    responses = tool_executor.batch(tool_invocations, return_exceptions=True)\n",
    "    tool_messages = [\n",
    "        ToolMessage(\n",
    "            content=str(response),\n",
    "            name=tc[\"name\"],\n",
    "            tool_call_id=tc[\"id\"],\n",
    "        )\n",
    "        for tc, response in zip(last_message.tool_calls, responses)\n",
    "    ]\n",
    "    return {\"messages\": tool_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "def first_model(state: agentstate):\n",
    "    human_input = state[\"messages\"][-1].content\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"tavily_search_results_json\",\n",
    "                        \"args\": {\n",
    "                            \"query\": human_input,\n",
    "                        },\n",
    "                        \"id\": \"tool_abcd123\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found edge starting at unknown node 'first_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m workflow\u001b[38;5;241m.\u001b[39madd_edge(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal\u001b[39m\u001b[38;5;124m\"\u001b[39m, END)\n\u001b[1;32m     21\u001b[0m memory \u001b[38;5;241m=\u001b[39m SqliteSaver\u001b[38;5;241m.\u001b[39mfrom_conn_string(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:memory:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m app \u001b[38;5;241m=\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/codeenv/lib/python3.11/site-packages/langgraph/graph/state.py:395\u001b[0m, in \u001b[0;36mStateGraph.compile\u001b[0;34m(self, checkpointer, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    392\u001b[0m interrupt_after \u001b[38;5;241m=\u001b[39m interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[1;32m    404\u001b[0m output_channels \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__root__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschemas[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m     ]\n\u001b[1;32m    413\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/codeenv/lib/python3.11/site-packages/langgraph/graph/graph.py:324\u001b[0m, in \u001b[0;36mGraph.validate\u001b[0;34m(self, interrupt)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;129;01mand\u001b[39;00m source \u001b[38;5;241m!=\u001b[39m START:\n\u001b[0;32m--> 324\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound edge starting at unknown node \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# assemble targets\u001b[39;00m\n\u001b[1;32m    327\u001b[0m all_targets \u001b[38;5;241m=\u001b[39m {end \u001b[38;5;28;01mfor\u001b[39;00m _, end \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_edges}\n",
      "\u001b[0;31mValueError\u001b[0m: Found edge starting at unknown node 'first_model'"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "workflow = StateGraph(agentstate)\n",
    "\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", call_tool)\n",
    "workflow.add_node(\"final\", call_tool)\n",
    "workflow.add_edge(START, \"first_model\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"first_model\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"action\",\n",
    "        \"final\": \"final\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "workflow.add_edge(\"final\", END)\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_U5TR77CYsr5JCh9IvVicntJ5', 'function': {'arguments': '{\"query\":\"weather in Jhelum, Punjab, Pakistan\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-667a4db3-f63e-4c31-88a4-19864a1cdec7-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Jhelum, Punjab, Pakistan'}, 'id': 'call_U5TR77CYsr5JCh9IvVicntJ5', 'type': 'tool_call'}])]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'action':\n",
      "---\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Jhelum\\', \\'region\\': \\'Punjab\\', \\'country\\': \\'Pakistan\\', \\'lat\\': 32.93, \\'lon\\': 73.73, \\'tz_id\\': \\'Asia/Karachi\\', \\'localtime_epoch\\': 1721645084, \\'localtime\\': \\'2024-07-22 15:44\\'}, \\'current\\': {\\'last_updated_epoch\\': 1721644200, \\'last_updated\\': \\'2024-07-22 15:30\\', \\'temp_c\\': 43.1, \\'temp_f\\': 109.5, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Patchy rain nearby\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/176.png\\', \\'code\\': 1063}, \\'wind_mph\\': 4.3, \\'wind_kph\\': 6.8, \\'wind_degree\\': 169, \\'wind_dir\\': \\'S\\', \\'pressure_mb\\': 994.0, \\'pressure_in\\': 29.36, \\'precip_mm\\': 0.03, \\'precip_in\\': 0.0, \\'humidity\\': 26, \\'cloud\\': 85, \\'feelslike_c\\': 47.7, \\'feelslike_f\\': 117.9, \\'windchill_c\\': 43.1, \\'windchill_f\\': 109.5, \\'heatindex_c\\': 47.7, \\'heatindex_f\\': 117.9, \\'dewpoint_c\\': 19.3, \\'dewpoint_f\\': 66.7, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 9.0, \\'gust_mph\\': 4.9, \\'gust_kph\\': 7.9}}\"}]', name='tavily_search_results_json', tool_call_id='call_U5TR77CYsr5JCh9IvVicntJ5')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_K3M8PJoAYBLdhLgfWmasmPOq', 'function': {'arguments': '{\"temperature\":43.1,\"other_notes\":\"The weather in Jhelum, Punjab, Pakistan is currently 43.1°C with patchy rain nearby. The humidity is 26% and the wind speed is 6.8 km/h coming from the south.\"}', 'name': 'Response'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-41fcdcdc-62e4-419a-ae43-e801080ca448-0', tool_calls=[{'name': 'Response', 'args': {'temperature': 43.1, 'other_notes': 'The weather in Jhelum, Punjab, Pakistan is currently 43.1°C with patchy rain nearby. The humidity is 26% and the wind speed is 6.8 km/h coming from the south.'}, 'id': 'call_K3M8PJoAYBLdhLgfWmasmPOq', 'type': 'tool_call'}])]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"what is the weather in Jhelum,punjab,pakistan?\")]}\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "while True:\n",
    "    for output in app.stream(inputs, config):\n",
    "        for key, value in output.items():\n",
    "            print(f\"Output from node '{key}':\")\n",
    "            print(\"---\")\n",
    "            print(value)\n",
    "        print(\"\\n---\\n\")\n",
    "    snapshot = app.get_state(config)\n",
    "    if not snapshot.next:\n",
    "        break\n",
    "    inputs = None\n",
    "    response = input(\n",
    "        \"Do you approve the next step? Type y if you do, anything else to stop: \"\n",
    "    )\n",
    "    if response != \"y\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
